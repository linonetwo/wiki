created: 20230809063813128
modified: 20230809081811375
tags: 知识图谱 组合式创新 调研适合在CPU上运行的配合个人知识库使用的语言模型
title: 结合语言模型和知识图谱

! 为什么还需要知识图谱

LLM里已经包括了大量知识，能让脑力劳动机械化，其所含知识大于等于现有知识图谱，而且有泛化能力。

但知识图谱更易于编辑，通过打MOD适配垂直领域（例如dnd），而且MOD可以很小（只含一个JSON）。

运行成本低，CPU上基本无感就能完成jsonschema验证。模块化也意味着人类可读性强（也意味着LLM也易读它），适合作为API规范，指导程序开发。

但LLM是生产力工具，KG必须结合它。

Unifying Large Language Models and Knowledge Graphs: A Roadmap 这篇综述中总结了几种做法：

! LLM增强KG

!! 对于rdf（或JSON，有没有ld都行）驱动的项目

配好提示词，靠LLM配合人工生成rdfs（对后续步骤影响大，需要人工检查，但工作量相比手写大大减少），下面的内容包括了生成rdfs和rdf。

# 对于微调类的需求，从头生成：结合提示词和rdfs，让LLM生成rdf
# 初始化图谱，从头生成：让LLM循环或递归运行，拆解蕴含的常识或领域知识，生成提示词，然后同上
# 初始化图谱，拆解文本：让LLM拆书，逻辑类似ChatPDF，但不是搜索而是精读提取每段文本为三元组
# 微调需求，联想：有研究尝试把kg拼入提示词，以实现KG补全[99]和KG推理[100]
# 整理知识：用SparQL等查找问题，然后让LLM遍历图谱中有问题的部分，做共指消解等
# 测试知识：普通测试人员也可以用LLM生成SparQL来检查kg可用性（反之也可以用KG生成填空题检查LLM可用性 LPAQA [125]）
# LLM作为推理机：除了上述的联想以外，在开发期预置NPC对话内容时，需要根据人设和能力图谱来生成文本以免角色出戏

! KG增强LLM

!! 训练时嵌入知识

# 有直接可用的高质量数据：训练或微调时拼入输入或验证里，需要通过可见矩阵等避免各种标记导致的知识噪声
# 知识图谱嵌入不善于表示未见实体和长尾关系[185]，[186]，还不如生成文本作为素材
# 长程关系：GLM [106]利用知识图谱的结构为掩码概率分配权重
# 数据增强：替换训练数据部分词为同近义词

!! 制造精于「LLM增强KG」的LLM

融入图谱信息：ERNIE [92]用双编码器同时学文本和对应的KG

!! 推理时使用图谱

在中间层里对图谱做筛选等等，这块没有作品达到特别好的效果